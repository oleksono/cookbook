{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-19T02:35:09.112729Z",
     "start_time": "2018-01-19T02:30:52.371593Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/01/18 20:31\n",
      "OS:  win32\n",
      "Python:  3.6.2 |Anaconda custom (64-bit)| (default, Jul 20 2017, 12:30:02) [MSC v.1900 64 bit (AMD64)]\n",
      "NumPy:  1.13.3\n",
      "Keras:  2.0.6\n",
      "Backend: TensorFlow 1.3.0\n",
      "[name: \"/gpu:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 1524796620\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 2752576944786943002\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 680, pci bus id: 0000:01:00.0\"\n",
      "]\n",
      "X_train shape: (60000, 28, 28, 1)\n",
      "60000 Training samples\n",
      "10000 Testing samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        832       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 20, 20, 32)        25632     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 20, 20, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 64)          18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 6, 6, 64)          36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              590848    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 1,732,586\n",
      "Trainable params: 1,732,586\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/12\n",
      "54000/54000 [==============================] - 14s - loss: 0.4143 - acc: 0.8630 - val_loss: 0.0639 - val_acc: 0.9823\n",
      "Epoch 2/12\n",
      "54000/54000 [==============================] - 13s - loss: 0.1110 - acc: 0.9660 - val_loss: 0.0451 - val_acc: 0.9868\n",
      "Epoch 3/12\n",
      "54000/54000 [==============================] - 13s - loss: 0.0806 - acc: 0.9746 - val_loss: 0.0392 - val_acc: 0.9887\n",
      "Epoch 4/12\n",
      "54000/54000 [==============================] - 13s - loss: 0.0682 - acc: 0.9785 - val_loss: 0.0329 - val_acc: 0.9897\n",
      "Epoch 5/12\n",
      "54000/54000 [==============================] - 13s - loss: 0.0621 - acc: 0.9805 - val_loss: 0.0303 - val_acc: 0.9910\n",
      "Epoch 6/12\n",
      "54000/54000 [==============================] - 12s - loss: 0.0533 - acc: 0.9833 - val_loss: 0.0310 - val_acc: 0.9908\n",
      "Epoch 7/12\n",
      "54000/54000 [==============================] - 13s - loss: 0.0489 - acc: 0.9846 - val_loss: 0.0301 - val_acc: 0.9922\n",
      "Epoch 8/12\n",
      "54000/54000 [==============================] - 12s - loss: 0.0461 - acc: 0.9857 - val_loss: 0.0308 - val_acc: 0.9915\n",
      "Epoch 9/12\n",
      "54000/54000 [==============================] - 78s - loss: 0.0418 - acc: 0.9867 - val_loss: 0.0320 - val_acc: 0.9917\n",
      "Epoch 10/12\n",
      "54000/54000 [==============================] - 29s - loss: 0.0399 - acc: 0.9873 - val_loss: 0.0254 - val_acc: 0.9917\n",
      "Epoch 11/12\n",
      "54000/54000 [==============================] - 12s - loss: 0.0364 - acc: 0.9883 - val_loss: 0.0325 - val_acc: 0.9907\n",
      "Epoch 12/12\n",
      "54000/54000 [==============================] - 13s - loss: 0.0352 - acc: 0.9890 - val_loss: 0.0272 - val_acc: 0.9918\n",
      "Total training time for 12 epochs: 240 seconds\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import advanced_activations\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import backend as K\n",
    "\n",
    "print(time.strftime('%Y/%m/%d %H:%M'))\n",
    "print('OS: ', sys.platform)\n",
    "print('Python: ', sys.version)\n",
    "print('NumPy: ', np.__version__)\n",
    "print('Keras: ', keras.__version__)\n",
    "\n",
    "# Printing backend and GPU information\n",
    "if keras.backend.backend() == 'tensorflow':\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.python.client import device_lib\n",
    "    print('Backend: TensorFlow', tf.__version__)\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    print([x for x in local_device_protos if x.device_type == 'GPU'])\n",
    "\n",
    "    # Avoiding memory issues with the GPU\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    sess = tf.Session(config=config)\n",
    "\n",
    "elif keras.backend.backend() == 'CNTK':\n",
    "    import cntk as C\n",
    "    print('Backend: CNTK', C.__version__)\n",
    "    print('GPU: ', c.gpu(0))\n",
    "\n",
    "\n",
    "# For tracking the training time for each epoch\n",
    "from keras import callbacks\n",
    "import time\n",
    "\n",
    "class TimeHistory(callbacks.Callback):\n",
    "    \"\"\"\n",
    "    Tracks training time on individual epochs for a Keras model\n",
    "    \"\"\"\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)\n",
    "\n",
    "\n",
    "time_callback = TimeHistory()\n",
    "\n",
    "# Model settings\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# Input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# Loading the data, shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Ensuring the channels are in the correct \n",
    "if K.image_data_format() == 'channels_first':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "# Setting data types and normalizing the images\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'Training samples')\n",
    "print(X_test.shape[0], 'Testing samples')\n",
    "\n",
    "# Converting class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "# Beginning model building\n",
    "model = Sequential()\n",
    "\n",
    "# Layer 1 - Conv (5x5)\n",
    "model.add(Conv2D(32, kernel_size=(5, 5), input_shape=input_shape))\n",
    "model.add(advanced_activations.LeakyReLU(alpha=0.03))\n",
    "\n",
    "# Layer 2 - Conv (5x5) & Max Pooling\n",
    "model.add(Conv2D(32, kernel_size=(5, 5)))\n",
    "model.add(advanced_activations.LeakyReLU(alpha=0.03))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Layer 3 - Conv (3x3)\n",
    "model.add(Conv2D(64, kernel_size=(3, 3)))\n",
    "model.add(advanced_activations.LeakyReLU(alpha=0.03))\n",
    "\n",
    "# Layer 4 - Conv (3x3) & Max Pooling\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(advanced_activations.LeakyReLU(alpha=0.03))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Layer 5 - FC 1024\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "\n",
    "# Layer 6 - FC 1024\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Defining loss function, optimizer, and metrics to report\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model before fitting\n",
    "model.summary()\n",
    "\n",
    "# Fitting the model\n",
    "model.fit(X_train, y_train,\n",
    "          epochs=epochs,\n",
    "          batch_size=128, verbose=1,\n",
    "          validation_split=0.1,  # Uses last 10% of data (not shuffled) for validation\n",
    "          callbacks=[time_callback])  # Gives epoch training times\n",
    "\n",
    "# Saving the model\n",
    "# model.save('model.h5')\n",
    "\n",
    "# Reporting total training time\n",
    "total_training_time = round(sum(time_callback.times))\n",
    "print('Total training time for {0} epochs: {1} seconds'.format(epochs, total_training_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-19T02:35:11.300232Z",
     "start_time": "2018-01-19T02:35:09.115729Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/01/18 20:35\n",
      "OS:  win32\n",
      "Python:  3.6.2 |Anaconda custom (64-bit)| (default, Jul 20 2017, 12:30:02) [MSC v.1900 64 bit (AMD64)]\n",
      "NumPy:  1.13.3\n",
      "CNTK:  2.1\n",
      "GPU:  GPU[0] GeForce GTX 680\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import cntk as C\n",
    "\n",
    "print(time.strftime('%Y/%m/%d %H:%M'))\n",
    "print('OS: ', sys.platform)\n",
    "print('Python: ', sys.version)\n",
    "print('NumPy: ', np.__version__)\n",
    "print('CNTK: ', C.__version__)\n",
    "print('GPU: ', C.gpu(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MXNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-20T00:37:05.203151Z",
     "start_time": "2017-12-20T00:37:05.190651Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-19T02:35:11.346229Z",
     "start_time": "2018-01-19T02:35:11.303228Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018/01/18 20:35\n",
      "OS:  win32\n",
      "Python:  3.6.2 |Anaconda custom (64-bit)| (default, Jul 20 2017, 12:30:02) [MSC v.1900 64 bit (AMD64)]\n",
      "NumPy:  1.13.3\n",
      "TensorFlow:  1.3.0\n",
      "[name: \"/gpu:0\"\n",
      "device_type: \"GPU\"\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 7322890844379714699\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 680, pci bus id: 0000:01:00.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "print(time.strftime('%Y/%m/%d %H:%M'))\n",
    "print('OS: ', sys.platform)\n",
    "print('Python: ', sys.version)\n",
    "print('NumPy: ', np.__version__)\n",
    "print('TensorFlow: ', tf.__version__)\n",
    "\n",
    "# Checking tensorflow processing devices\n",
    "from tensorflow.python.client import device_lib\n",
    "local_device_protos = device_lib.list_local_devices()\n",
    "print([x for x in local_device_protos if x.device_type == 'GPU'])\n",
    "\n",
    "# Avoiding memory issues with the GPU\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
